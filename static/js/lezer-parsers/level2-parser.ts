// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {specializeKeyword} from "./tokens"
export const parser = LRParser.deserialize({
  version: 14,
  states: "&`QVQPOOOOQO'#Cp'#CpQVQPOOOnQPO'#CgOOQO'#Cu'#CuOsQPO'#CjOOQO'#Cv'#CvO{QPO'#ClOOQO'#Cw'#CwO!TQPO'#CmOOQO'#Cx'#CxO!]QPO'#CnOOQO'#Ck'#CkOOQO'#Cy'#CyO!eQPO'#CoOOQO'#Cf'#CfQiQPO'#CqQ!mQPOOOOQO-E6n-E6nOOQO'#Cr'#CrO#RQPO,59ROOQO'#Cs'#CsO#^QPO,59UOOQO-E6s-E6sOOQO-E6t-E6tOOQO,59W,59WOOQO-E6u-E6uOOQO,59X,59XOOQO-E6v-E6vOOQO,59Y,59YOOQO-E6w-E6wOOQO,59Z,59ZO#iQPO,59]OOQO-E6o-E6oOOQO-E6p-E6pO$TQPO1G.mOOQO'#Ct'#CtO$`QPO1G.oOOQO-E6q-E6qO$hQPO7+$ZOOQO-E6r-E6r",
  stateData: "$s~OWOS~OQSORUOSWOTYOU]O[ROpPO~OVcO~OQSO[eO~ORUO[iO~OSWO[kO~OTYO[mO~OU]O[oO~OQSORUOSWOTYOU]O[RO~OPtOVcO[eO~O[eOn^ap^a~OpPOQeaReaSeaTeaUea[eanea~O[eOnZipZi~OPtO[eO~O[eOn]qp]q~O",
  goto: "#unPPPPPPPPPPotPtttyyyt!O!Y!a!g!u!{#T#]#e#mV`OQaV_OQaV[OQaQQOSbQpRp`SaOQRqaQdRRrdQfTQsdUvfswRwuQudRxuUTOQaRgTUVOQaRhVUXOQaRjXUZOQaRlZU^OQaRn^",
  nodeNames: "âš  ask print forward turn color sleep is Comment Program Command Assign Text Ask Print Turtle Forward Turn Color Sleep",
  maxTerm: 32,
  nodeProps: [
    ["group", 15,"turtle"]
  ],
  skippedNodes: [0,8],
  repeatNodeCount: 10,
  tokenData: "!v~RWOYkYZ!YZpkqskst!_t;'Sk;'S;=`!S<%lOk~pU[~OYkZpkqskt;'Sk;'S;=`!S<%lOk~!VP;=`<%lk~!_Op~~!dSW~OY!_Z;'S!_;'S;=`!p<%lO!_~!sP;=`<%l!_",
  tokenizers: [0],
  topRules: {"Program":[0,9]},
  specialized: [{term: 12, get: (value: any, stack: any) => (specializeKeyword(value, stack) << 1) | 1, external: specializeKeyword, extend: true}],
  tokenPrec: 0
})
